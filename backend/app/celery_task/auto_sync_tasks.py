import asyncio
from celery import group
from datetime import datetime
from app.celery_worker import celery_app
from app.database.database import SessionLocal
from app.database import crud, models
from app.service.facebook_api import fb_get
from app.service.auto_sync_service import auto_sync_service
from app.celery_task.customer_tasks import handle_new_customer_task, handle_existing_customer_task
import logging

logger = logging.getLogger(__name__)

@celery_app.task(bind=True, autoretry_for=(Exception,), retry_backoff=True, retry_kwargs={'max_retries': 3})
def sync_all_pages_task(self):
    """
    Task ‡∏´‡∏•‡∏±‡∏Å: ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏∏‡∏Å‡πÄ‡∏û‡∏à (‡πÄ‡∏£‡∏µ‡∏¢‡∏Å subtask ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏û‡∏à)
    """
    db = SessionLocal()
    try:
        pages = db.query(models.FacebookPage).all()
        logger.info(f"üöÄ Celery started syncing {len(pages)} pages")

        for page in pages:
            token_entry = auto_sync_service.page_tokens.get(page.page_id)
            if not token_entry:
                logger.warning(f"‚ö†Ô∏è No token found for page_id={page.page_id}")
                continue

            sync_page_conversations_task.delay(page.page_id, token_entry)

        return {"status": "scheduled", "page_count": len(pages)}
    finally:
        db.close()


@celery_app.task(bind=True)
def sync_page_conversations_task(self, page_id: str, access_token: str):
    """
    Task: ‡∏î‡∏∂‡∏á conversations ‡∏Ç‡∏≠‡∏á‡πÄ‡∏û‡∏à‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡πÅ‡∏•‡πâ‡∏ß‡∏™‡πà‡∏á‡πÑ‡∏õ process_conversation_task
    """
    db = SessionLocal()
    try:
        logger.info(f"üîÅ Syncing page {page_id}")

        page = crud.get_page_by_page_id(db, page_id)
        if not page:
            return {"error": f"Page not found: {page_id}"}

        endpoint = f"{page_id}/conversations"
        params = {
            "fields": "participants,updated_time,id,messages.limit(10){created_time,from,message,id}",
            "limit": 100
        }

        result = fb_get(endpoint, params, access_token)
        if "error" in result:
            return {"error": result["error"]}

        conversations = result.get("data", [])
        logger.info(f"üì® Found {len(conversations)} conversations for page {page_id}")

        job_group = group(
            process_conversation_task.s(convo, page_id, access_token)
            for convo in conversations
        )
        result_group = job_group.apply_async()

        return {"status": "queued", "page_id": page_id, "conversation_count": len(conversations)}

    except Exception as e:
        logger.error(f"‚ùå Error syncing page {page_id}: {e}")
        raise
    finally:
        db.close()

@celery_app.task(bind=True, autoretry_for=(Exception,), retry_backoff=True, retry_kwargs={'max_retries': 3})
def process_participant_task(self, participant_data, page_id, convo_id, access_token):
    """
    ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏ô (participant)
    """
    db = SessionLocal()
    try:
        participant_id = participant_data.get("id")
        name = participant_data.get("name")

        logger.info(f"üë§ [Participant] Processing {name} ({participant_id})")

        page = crud.get_page_by_page_id(db, page_id)
        if not page:
            return {"error": f"page_id {page_id} not found"}

        existing = crud.get_customer_by_psid(db, page.ID, participant_id)
        if existing:
            # ‚úÖ ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÄ‡∏Å‡πà‡∏≤ ‚Üí ‡πÉ‡∏´‡πâ Celery ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï
            msg_time = datetime.now().isoformat()
            handle_existing_customer_task.delay(page_id, participant_id, msg_time)
            logger.info(f"üìù Queued existing customer update for {participant_id}")
        else:
            # üÜï ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÉ‡∏´‡∏°‡πà ‚Üí ‡πÉ‡∏´‡πâ Celery ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á
            handle_new_customer_task.delay(page_id, participant_id, name, convo_id, access_token)
            logger.info(f"üÜï Queued new customer creation for {participant_id}")

        return {"status": "queued", "participant": participant_id}

    except Exception as e:
        logger.error(f"‚ùå Error processing participant {participant_data}: {e}")
        raise
    finally:
        db.close()

# ‚úÖ Task ‡∏£‡∏∞‡∏î‡∏±‡∏ö conversation
@celery_app.task(bind=True)
def process_conversation_task(self, convo_data, page_id, access_token):
    """
    ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞ conversation (‡πÄ‡∏£‡∏µ‡∏¢‡∏Å task ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏ô)
    """
    try:
        convo_id = convo_data.get("id")
        participants = convo_data.get("participants", {}).get("data", [])

        logger.info(f"üí¨ [Conversation] Processing {convo_id} ({len(participants)} participants)")

        from celery import group

        job_group = group(
            process_participant_task.s(participant, page_id, convo_id, access_token)
            for participant in participants
            if participant.get("id") and participant.get("id") != page_id
        )

        result = job_group.apply_async()
        logger.info(f"üì§ Dispatched {len(participants)} participant tasks for convo={convo_id}")

        return {"status": "queued", "convo_id": convo_id, "participants": len(participants)}
    except Exception as e:
        logger.error(f"‚ùå Error processing conversation {convo_data}: {e}")
        raise