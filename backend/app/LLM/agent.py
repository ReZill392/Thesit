import re
import requests
from io import BytesIO
from datetime import datetime, timezone
from sqlalchemy.orm import Session
import google.generativeai as genai
from PIL import Image
from app.database import models
import asyncio
import time
import random

# simple cache
_cache_text = {}
_cache_image = {}


def classify_and_assign_tier_hybrid(db: Session, page_id: int):
    # 1Ô∏è‚É£ ‡πÇ‡∏´‡∏•‡∏î knowledge config ‡∏ó‡∏µ‡πà enabled
    enabled_knowledge_ids = [
        pk.customer_type_knowledge_id
        for pk in db.query(models.PageCustomerTypeKnowledge)
        .filter(
            models.PageCustomerTypeKnowledge.page_id == page_id,
            models.PageCustomerTypeKnowledge.is_enabled == True
        )
        .all()
    ]

    knowledge_map = {
        ck.id: ck
        for ck in db.query(models.CustomerTypeKnowledge)
        .filter(models.CustomerTypeKnowledge.id.in_(enabled_knowledge_ids))
        .all()
    }

    # 2Ô∏è‚É£ ‡πÇ‡∏´‡∏•‡∏î tier config
    tier_configs = (
        db.query(models.RetargetTiersConfig)
        .filter(models.RetargetTiersConfig.page_id == page_id)
        .order_by(models.RetargetTiersConfig.days_since_last_contact.asc())
        .all()
    )

    customers = (
        db.query(models.FbCustomer)
        .filter(models.FbCustomer.page_id == page_id)
        .all()
    )

    now = datetime.now(timezone.utc)
    pending_updates = []

    for cust in customers:
        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
        last_message = (
            db.query(models.CustomerMessage.message_text,
                     models.CustomerMessage.message_type)
            .filter(models.CustomerMessage.customer_id == cust.id)
            .order_by(models.CustomerMessage.created_at.desc())
            .first()
        )
        if not last_message:
            continue

        message_text, message_type = last_message
        if not message_text:
            continue

        # 3Ô∏è‚É£ Classification (text ‚Üí keyword ‚Üí Gemini, attachment ‚Üí image classifier)
        category_id = None

        if message_type == "text":
            category_id = match_by_keyword(message_text, knowledge_map)
            if not category_id:
                category_id = classify_with_gemini(message_text, knowledge_map)  # ‚úÖ ‡πÉ‡∏ä‡πâ‡πÄ‡∏ï‡πá‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° + flash-lite default

        elif message_type == "attachment":
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö query string ‡∏ï‡πà‡∏≠‡∏ó‡πâ‡∏≤‡∏¢)
            if re.search(r'\.(png|jpe?g)(\?.*)?$', message_text, re.IGNORECASE):
                category_id = classify_with_gemini_image(message_text, knowledge_map)

        # 4Ô∏è‚É£ Update knowledge id ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô
        if category_id and category_id != cust.customer_type_knowledge_id:
            cust.customer_type_knowledge_id = category_id

            knowledge_type = db.query(models.CustomerTypeKnowledge).filter(
                models.CustomerTypeKnowledge.id == category_id
            ).first()
            page_record = db.query(models.FacebookPage).filter(
                models.FacebookPage.ID == page_id
            ).first()

            if knowledge_type and page_record:
                update_data = {
                    'page_id': page_record.page_id,
                    'psid': cust.customer_psid,
                    'customer_type_knowledge_id': category_id,
                    'customer_type_knowledge_name': knowledge_type.type_name,
                    'timestamp': datetime.now(timezone.utc).isoformat()
                }
                pending_updates.append(update_data)

        # 5Ô∏è‚É£ ‡∏´‡∏≤ tier ‡∏à‡∏≤‡∏Å‡∏ß‡∏±‡∏ô
        if cust.last_interaction_at:
            days_since_last = (now - cust.last_interaction_at).days
            selected_tier = None
            for tier in sorted(tier_configs, key=lambda x: x.days_since_last_contact):
                if days_since_last >= tier.days_since_last_contact:
                    selected_tier = tier.tier_name
            if selected_tier:
                cust.current_tier = selected_tier

    # ‚úÖ Commit ‡∏Å‡πà‡∏≠‡∏ô
    db.commit()

    # ‚úÖ ‡∏™‡πà‡∏á SSE ‡∏´‡∏•‡∏±‡∏á commit ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
    if pending_updates:
        try:
            from app.routes.facebook.sse import customer_type_update_queue

            async def send_all():
                for update in pending_updates:
                    await customer_type_update_queue.put(update)
                    print(f"üì° Queueing SSE update: {update['psid']} -> {update['customer_type_knowledge_name']}")

            # ‡πÉ‡∏ä‡πâ existing loop ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ, ‡πÑ‡∏°‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á
            try:
                loop = asyncio.get_running_loop()
                loop.create_task(send_all())
            except RuntimeError:
                asyncio.run(send_all())

        except Exception as e:
            print(f"‚ùå Error sending SSE updates: {e}")


def match_by_keyword(message_text: str, knowledge_map: dict):
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢ keyword ‡∏Å‡πà‡∏≠‡∏ô ‡∏ñ‡πâ‡∏≤ match ‡∏Å‡πá return category id"""
    for k in knowledge_map.values():
        if not k.keywords:
            continue
        for kw in k.keywords:
            if re.search(r'\b' + re.escape(kw) + r'\b', message_text, re.IGNORECASE):
                print(f"Keyword matched: '{kw}' -> Category ID: {k.id}")
                return k.id
    return None


def safe_extract_text(response):
    """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å Gemini response ‡πÅ‡∏ö‡∏ö‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢"""
    if not response.candidates:
        return None, "no_candidates"

    cand = response.candidates[0]
    if cand.finish_reason != 1:  # 1 = SUCCESS
        return None, f"finish_reason={cand.finish_reason}"

    if not cand.content.parts:
        return None, "no_parts"

    return cand.content.parts[0].text.strip(), None

def classify_with_gemini(
    message_text: str,
    knowledge_map: dict,
    max_retries: int = 3,
    model_name: str = "gemini-2.5-flash-lite"  # üëà default ‡∏Ñ‡∏∑‡∏≠ flash-lite
):
    if message_text in _cache_text:
        return _cache_text[message_text]

    prompt_parts = [
        "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ä‡∏ó",
        "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏µ‡πâ",
        "\n--- ‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ---"
    ]
    for k in knowledge_map.values():
        prompt_parts.append(f"ID {k.id}: {k.type_name} (‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢: {k.rule_description}) (‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: {k.examples})")

    prompt_parts.append("\n--- ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ ---")
    prompt_parts.append(message_text)
    prompt_parts.append(
        """--- ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á ---
        1. ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏Å‡∏±‡∏ö "‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á" ‡∏Ç‡∏≠‡∏á‡∏´‡∏°‡∏ß‡∏î‡πÉ‡∏î ‡πÉ‡∏´‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏°‡∏ß‡∏î‡∏ô‡∏±‡πâ‡∏ô‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
        2. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏´‡∏°‡∏ß‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
        3. ‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏°‡∏ß‡∏î‡∏≠‡∏∑‡πà‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á
        4. ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç ID ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß"""
    )

    prompt = "\n".join(prompt_parts)

    for attempt in range(max_retries):
        try:
            model = genai.GenerativeModel(
                model_name=model_name,
                generation_config={"temperature": 0, "max_output_tokens": 20}
            )
            response = model.generate_content(prompt)

            answer, err = safe_extract_text(response)
            if not answer:
                print(f"‚ö†Ô∏è Gemini {model_name} returned no usable text ({err})")
                if "finish_reason=2" in (err or "") and attempt < max_retries - 1:
                    time.sleep(1 + random.random())
                    continue
                return None

            match = re.search(r'\d+', answer)
            if match and int(match.group(0)) in knowledge_map:
                category_id = int(match.group(0))
                print(f"Gemini classified text into Category ID: {category_id} (via {model_name})")
                _cache_text[message_text] = category_id
                return category_id
            else:
                print(f"‚ö†Ô∏è Gemini {model_name} returned invalid answer: {answer}")
                return None

        except Exception as e:
            err_msg = str(e)
            if "429" in err_msg and attempt < max_retries - 1:
                wait_time = (2 ** attempt) + random.uniform(0, 1)
                print(f"‚è≥ Gemini {model_name} rate limited. Retrying in {wait_time:.1f}s...")
                time.sleep(wait_time)
                continue
            else:
                print(f"‚ùå Gemini {model_name} API error: {e}")
                return None

    return None

def classify_with_gemini_image(image_url: str, knowledge_map: dict, max_retries: int = 3):
    """‡πÉ‡∏ä‡πâ Gemini Vision ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏†‡∏≤‡∏û + retry/backoff + cache"""

    # üîπ check cache ‡∏Å‡πà‡∏≠‡∏ô
    if image_url in _cache_image:
        return _cache_image[image_url]

    try:
        # ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏à‡∏≤‡∏Å url
        img_bytes = requests.get(image_url, timeout=10).content
        image = Image.open(BytesIO(img_bytes))

    except Exception as e:
        print(f"‚ùå Error loading image: {e}")
        return None

    model = genai.GenerativeModel("gemini-1.5-flash")

    for attempt in range(max_retries):
        try:
            response = model.generate_content(
                [
                    image,
                    "\n‡πÇ‡∏õ‡∏£‡∏î‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡∏ô‡∏µ‡πâ‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡∏ß‡πà‡∏≤‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£ ‡πÄ‡∏ä‡πà‡∏ô slip, receipt, ‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤, ‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏≠‡∏∑‡πà‡∏ô"
                ]
            )
            caption = response.text.strip()
            print(f"Gemini Vision caption: {caption}")

            # ‡∏™‡πà‡∏á caption ‡πÄ‡∏Ç‡πâ‡∏≤ classifier ‡πÅ‡∏ö‡∏ö text
            category_id = classify_with_gemini(caption, knowledge_map)
            if category_id:
                _cache_image[image_url] = category_id
            return category_id

        except Exception as e:
            err_msg = str(e)
            if "429" in err_msg and attempt < max_retries - 1:
                wait_time = (2 ** attempt) + random.uniform(0, 1)
                print(f"‚è≥ Gemini image rate limited. Retrying in {wait_time:.1f}s...")
                time.sleep(wait_time)
                continue
            else:
                print(f"‚ùå Gemini image API error: {e}")
                return None

    return None